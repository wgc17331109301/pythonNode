# 数据分析流程

**明确目标   >   数据处理   >   数据分析   >   数据展现   >   报告撰写**

# 一、Pandas模块

```python
import pandas as pd
```

### 1、pandas库介绍

`pandas` 库是一个专门用来解决数据分析问题的库

优势：

​	1、速度快：快速处理大型数据集；

​	2、效率高：提供大量高效处理数据的函数和方法。

### 2、基本数据结构

##### Series

- 概念

  ```python
  1、Series 主要由一组数据及其对应的索引组成。
  2、Series  对象左侧的是索引，右侧的是数据。
  3、dtype：object（字符串）
  ```

- 创建Series对象：

  语法：pd.Series(data,index)

  > data：创建Series对象所需要的数据，可以为列表
  >
  > index：设置Series对象的列索引

  ```python
  # pd.Series(data)
  surname = pd.Series(['赵', '钱', '孙', '李'], index = ['学生1', '学生2', '学生3', '学生4'])
  ```

- **将 series 类型的数据转换成 dataframe：**

  ```python
  Series.to_frame()
  ```

- 将series 数据转换为列表

  ```python
  Series.to_list()
  ```

##### DataFrame

- 概念

  ```python
  1、DataFrame 对象是一种表格型的数据结构，包含行索引、列索引以及一组数据。
  2、DataFrame 对象可以看作是由 Series 对象所组成的。
  ```

- 创建DataFranme对象：

  语法：pd.DataFrame(data)

  > data：创建DataFrame 对象所需要的数据，可以为字典
  >
  > 
  >
  > 注：可以通过append方法对有同样列名的 DataFrame 数据进行整合
  
  ```python
  # pd.DataFrame(data,columns)
  class_df = pd.DataFrame({'年龄': [25, 18, 23, 18],
                           '性别': ['女', '女', '女', '男']})
  ```
  

- **合并 DataFrame数据**

  ```python
  语法：df_1.merge(df_2, on=None, how='inner')
  ```

  > 参数说明：
  >
  > df_1 为待合并的第一份数据表；df_2 为待合并的第二份数据表；
  >
  > on 参数用于确认两个数据表连接的键，会选择两者都有的数据作为键，比如两个数据表都有'symbol_exchange'列，就可以用这一列数据作为键；
  >
  > how 参数用于取交集还是取并集，'inner'为交集，'outer'为并集，当 how 为'inner'时，会保留 df_1 和 df_2 中作为键那一列共有的数据，如果只有 df_1 有或者只有 df_2 有的话，就会丢弃。

- pct_change 计算相差百分比

  ```python
  语法：DataFrame.pct_change(periods=1, fill_method=‘pad’, limit=None, freq=None, **kwargs)
  ```

  > 表示当前元素与先前元素的相差百分比
  >
  > 参数：
  >
  > periods=n,表示当前元素与先前n 个元素的相差百分比。

  - 例子

    ```python
    import pandas as pd
    df = pd.DataFrame({
              'data1': [4,5, 6,7],
                'data2': [10,20,30,40],
                'data3': [500, 600, 700,800]},
        )
    df.pct_change(periods=2)
    ```

##### 列操作

- 提取某一列数据：

  ```python
  # df['列索引']
  class_df['年龄']
  ```

- 添加新列：

  语法：df[columns] = Series

  ```python
  df['新列'] = S
  ```

- **修改列名：**

  ```python
  df.columns = [新列名列表]
  ```

  > 修改全部列名

- 修改指定列名

  ```python
  df.rename(columns= {'原列名':'新列名'})
  ```

  > ！！！一定要加   columns

- 遍历数据：

  ```python
  # iterrows() 是在数据框中的行进行迭代的一个生成器，它返回每行的索引及一个包含行本身的对象。
  
  for index, row in products_dist.iterrows():
      print(row)
      g.text(row.name,row['订单数占比'], round(row['订单数占比'],2), color='red', ha="center")
  ```
  
  > index：返回每行的索引
  >
  > row：包含行本身的对象。如下
  >
  > ```
  > 商品数       1.00
  > 订单数占比    87.09
  > Name: 0, dtype: float64
  > 商品数      2.00
  > 订单数占比    4.86
  > Name: 1, dtype: float64
  > 商品数      3.00
  > 订单数占比    0.51
  > Name: 2, dtype: float64
  > 商品数      4.00
  > 订单数占比    0.19
  > Name: 3, dtype: float64
  > 商品数      5.00
  > 订单数占比    0.02
  > Name: 4, dtype: float64
  > ```

### 3、文件读写

- 读取

  csv语法：pd.read_csv(path,encoding)

  > path：文件路径
  >
  > encoding：编码格式

  ```python
  # 导入csv 文件，返回一个DataFrame 对象。
  df = pd.read_csv('./工作/mask_data.csv', encoding = 'utf-8')
  ```

  excel语法：pd.read_excel(path,sheet_name)

  > path：文件路径
  >
  > sheet_name：指定读取的工作表，默认第一个。

  ```python
  # 导入excel 文件，返回一个 DataFranme 对象。
  data_1 = pd.read_excel('./工作/成绩单.xlsx', sheet_name='1 班')
  ```

  

- 保存数据

  csv语法：pd.to_csv(path,encoding,index)

  > path：保存的路径
  >
  > encoding：编码格式
  >
  > index：是否保留索引，默认True保留

```python
# 将 DataFrame 以csv文件导出
df.to_csv('./工作/mask_data_clean.csv', index = False		
```

​		excel语法：pd.to_excel(path,sheet_name,index)

```python
# 将 DataFrame 以 excel 文件导出
data_2.to_excel('新成绩单.xlsx', sheet_name='2 班', index=False)
```

参数：

| **path**       | **设置文件路径**          |
| -------------- | ------------------------- |
| **encoding**   | **设置编码格式**          |
| **index**      | **默认True保留行索引**    |
| **sheet_name** | **excel文件指定工作表名** |

### 4、转换日期格式

**功能：将字符串格式的时间数据转换为 datetime 对象。**

**语法：pd.to_datetime(arg, format)**

| arg                   | 要转换的数据                |
| --------------------- | --------------------------- |
| **format**            | **datetime 类型的日期格式** |
| **errors = 'coerce'** | **排除异常值**              |

```python
# 转换日期数据，并设置对应的日期格式
date_data = pd.to_datetime(mask_data['日期'], format = '%Y-%m-%d')
```

**提取信息：**

**语法：Series.dt.方法**

| **s.dt.year**    | **返回年份信息**      |
| ---------------- | --------------------- |
| **s.dt.month**   | **返回月份信息**      |
| **s.dt.day**     | **返回某日信息**      |
| **s.dt.weekday** | **返回星期信息(0-6)** |

```python
# 提取日期数据中的月份信息
month_data = date_data.dt.month
```

**方法二：详见第四点类型转换**

###  5、pandas绘图

**语法：Series.plot(kind,figsize,title)**

> kind：图表类型，常用的有 'line'折线图，‘bar’条形图，‘pie’饼图，‘scatter’散点图
>
> 
>
> figsize：图标尺寸，figsize=（宽，高）
>
> title：图表标题，一段字符串。

| 参数       | 说明                          | 使用示例           |
| ---------- | ----------------------------- | ------------------ |
| user_index | 是否要用行索引作为x轴的刻度值 | user_index = False |
| xticks     | 设置横坐标的值                | xticks = [0]       |
| yticks     | 设置纵坐标的值                | yticks = [9]       |
| rot        | 设置刻度值的旋转角度          | rot = 30           |
| fontsize   | 设置刻度值的字体大小          | fontsize = 20      |

**折线图：DataFrame.plot.line(self, x=None, y=None, **kwargs)**

```python
# 构造数据
test_dict = {'销售量':[1000,2000,5000,2000,4000,3000],'收藏':[1500,2300,3500,2400,1900,3000]}
monthly_info = pd.DataFrame(test_dict, index = ['一月','二月','三月','四月','五月','六月'])

monthly_info.plot.line()
# 带有子图
monthly_info.plot.line(subplots=True)
```

**条形图：DataFrame.plot.bar(self, x=None, y=None, **kwargs)**

```python
# 垂直条形图
monthly_info.plot.bar()
# 水平条形图
monthly_info.plot.barh()
```

**饼图：**

```python
# 1.subplots 为必要参数设置为True，当然也可以指定y的值。2.figsize 图⽚的⼤⼩。3.autopct 显示百分⽐。4.radius 圆的半径。5.startangle 旋转⻆度。6.legend 图例。7.colormap 颜⾊。
monthly_info.plot.pie(subplots=True,figsize=(10, 8),autopct='%.2f%%',radius = 1.2,startangle = 250,legend=False,colormap='viridis')
```

# 二、Numpy库

```python
import numpy as np
```

### 1、概念

概念：NumPy是⼀个开源的Python科学计算基础库，还是 Scipy、Pandas 等数据处理或科学计算库的基础 ，它被⽤于⽤于科学计算，且在性能、存储⽅⾯都具有⼀定优势。

作用：1、由预编译好的 C 代码快速执⾏计算，故⽐之Python，它的运算速度更快。2、有更好的存储结构来提⾼计算效率。

### 2、数组

一维数据：⼀般是由线性⽅式组织的数据构成如 Python 中的列表，只能从列这⼀个⻆度去描述数据。（像python列表）

⼆维数据：由多个⼀维数据构成，是⼀维数据的组合如嵌套列表表示的表格，可以从⾏列两个维度描述。（如嵌套列表）

三维数据：由⼀维数据/⼆维数据在新维度上扩展形成如再更多⼀层的列表嵌套。（再多一层的嵌套列表）

**常用方法：**

| 函数                               | 参数                               | 说明                                                         | 语法案例                     |
| ---------------------------------- | ---------------------------------- | ------------------------------------------------------------ | ---------------------------- |
| np.array（列表/元组…）             | 创建ndarray数组                    | 传⼏维的 Python 数据进 array() ⽅法中，就会⽣成⼏维的 ndarray 数组出来。 | np.array([1,2,3])            |
| np.arange(stop,end,步长)           | 用于描述数组长度的整数             | 类似range()函数，返回ndarray类型                             | np.arange(3)                 |
| np.ones(shape)                     | 用于描述数组形状的元组             | 根据shape生成一个全1数组，shape可以是元组类型，适用于生成固定形状的数组 | np.ones((3,4))               |
| np.zeros(shape)                    | 用于描述数组形状的元组             | 根据shape生成一个全0数组                                     | np.zeros((3,4))              |
| np.full(shape,fill_value)          | 用于描述数组形状的元组，及元素的值 | 根据shape生成一个数组，每个元素值都是fill_value，适用于生成固定形状及元素值的数组 | np.full((3,4),1)             |
| np.eye(N)                          | 用于描述数组形状的整数             | 创建一个正方的N*N单位矩阵，对角线为1，其余为0                | np.eye(3)                    |
| np.empty(shape)                    | 创建⼀个没有任何具体值的数组       | 同zeros、ones用法一样                                        | np.empty((3,4))              |
| np.linspace(start,end,number)      | 创建⼀个⼀维数组                   | 通过指定开始值、终值和元素个数来创建⼀个⼀维数组，数组的数据元素符合等差数列。 | np.linspace(1,10,5)          |
| np.logspace(start,end,number,base) | 创建等⽐数列的数组                 | 和 linspace 函数类似，base：表示等⽐数列的公⽐               | np.logspace(1,10,5,base=2)   |
| np.random.random(shape)            | 生成随机数列                       | 用来创建0-1之间的随机元素，数组包含的元素数量由参数决定      | np.random.random([4,4])      |
| np.random.randint(start,end,shape) | 生成随机数列                       | 创建整数随机元素，start与end之间                             | np.random.randint(0,2,[4,4]) |

**数组类型**

```python
# 查看数据类型
print(array_3.dtype)
```

| 属性  | 说明                       |
| ----- | -------------------------- |
| int   | 包括8-64位长度的整数       |
| float | 包括16-64位长度的浮点数    |
| unit  | 包括8-64位长度的无符号整数 |
| bool  | 布尔类型                   |

### 3、数组属性

| 函数                                   | 说明                                                         |
| -------------------------------------- | ------------------------------------------------------------ |
| data.shape                             | 表示数组的形状，调⽤时返回⼀个元组作为结果                   |
| data.size                              | 表示数组的轴/维度的数量，调⽤时返回⼀个整数作为结果          |
| data.adim                              | 表示数组的元素个数，调⽤时返回⼀个整数作为结果               |
| data.reshape(arr, newshape, order='C') | 在不改变数据的条件下修改数组的形状,order：'C' -- 按⾏，'F' -- 按列，'A' -- 原顺序，'k' -- 元素在内存中的出现顺序。 |
| data.resize(arr, shape)                | 返回指定形状的新数组。如果新数组⼤⼩⼤于原始⼤⼩，则包含原始数组中的元素的副本。 |

```
data.reshape(4,2)
```

### 4、数组索引

一维数组索引语法：ndarray[索引值0]⽤法

多维数组索引语法：ndarray[索引值0,索引值1…]⽤法

```python
# 查看数组中值为 2 的元素
array_1[1]
# 索引二维数组中第3行第2列的元素
array_2[2, 1]
```

组合不同索引的索引切⽚：语法：ndarray[起点索引值: 终点索引值: 步⻓]

布尔索引语法：ndarray[布尔数组]

```python
booling_1 = array_1 < 22
array_1[booling_1]
```

### 5、数组计算

**向量运算：**

1】两个数组形状相同时，它们内部对应位置的元素将⼀⼀对应做加减乘除

2】两个形状不同数组间运算时，它们对应维度的元素数量必须相同，或者其中⼀⽅为1,才可以运算成功

**数组计算函数：**

| 函数          | 说明       | 使用案例            |
| ------------- | ---------- | ------------------- |
| np.add()      | 加法       | np.add(data,3)      |
| np.divide()   | 除法       | np.divide(data,3)   |
| np.power()    | 平分       | np.power(data,3)    |
| np.multiply() | 乘法       | np.multiply(data,3) |
| abs()         | 绝对值函数 | abs(data)           |

```python
# 或者直接运算,数组 + 运算
data + 3
data * 3
```

**三角函数：**

```python
theta = np.linspace(0,np.pi,3)

np.sin(theta)
np.cos(theta)
np.tan(theta)
# 反三角函数
np.arctan()
```

**指数对数函数：**

```python
L2 = [1,2,3]
# 指数运算
np.exp(L2)
# 以e位底的对数运算
np.log(L2)
# 以2为底的对数运算
np.log2(L2)
# 以10为底的对数运算
np.log10(L2)
```

# 三、数据清洗

### 1、常用方法

| **df.info()**        | **查看数据基本结构**，字段的情况、总行数和存储大小、某列的数据类型、是否有空行等。 |
| -------------------- | ------------------------------------------------------------ |
| **df.head(row)**     | **查看数据前几行，默认5行，可以给row传值，则会显示指定行数** |
| **df.hail()**        | **查看数据最后几行，同head方法**                             |
| **df.describe()**    | **对数据类型为数值型的列进行，描述性统计信息(频数统计、平均值、标准差、最小值等)** |
| **s.unstack(level)** | **将一个多层分组聚合后的 Series 对象转变成 DataFrame 对象，level设置为0则为列** |

### 2、缺失值

| **s/df.isna()**                    | **查找缺失值，返回布尔值（True表示缺失）**                   |
| ---------------------------------- | ------------------------------------------------------------ |
| **df.dropna(subset,axis,inplace)** | **删除 DataFrame 中包含空值的行或列<br>subset：指定删除的列（列表）<br>axis：默认为0（删除行），为1则删除列<br>inplace：如果为True，删除了空值后会覆盖原对象，为False则不会** |
| **s/df.fillna(指定数据)**          | **填充缺失值，将 DataFrame 中所有为 NaN的数据替换为指定的数据。** |
| **s/df.isna().values**             | **获取数组对象**                                             |
| **df.isnull()**                    | **查找缺失值，同isna**                                       |
| **df.isnull().sum()**              | **计算缺失值的个数**                                         |
| **df.isnull().any(axis=1)**        | **如果每一行中至少有一个True，则将此行标记为True**           |

```python
# 查看空值
data[data.isna().values]
```

### 3、重复值

| **df.duplicated()**             | **查找重复值，返回布尔值（重复为True）**<br>重复指的是两行数据所有字段对应的数据都相同。 |
| ------------------------------- | ------------------------------------------------------------ |
| **df[df.duplicated()]**         | **查看重复数据**                                             |
| **df.drop_duplicates(inplace)** | **删除重复值**<br>inplace：是否覆盖原对象                    |

### 4、异常值

**先使用df.describe()，对数据类型为数值型的列进行描述性统计并输出结果。**

##### 方法一：筛选条件

**语法：df[df[columns]条件判断式]**

```python
# df = df[范围]
# 筛选出文化课总分大于100  或  素质课总分小于0的数据
df[(df['文化课总分'] > 100) | (df['素质课总分'] < 0)]
```

##### 方法二：删除指定行或列

**语法：df.drop(index,columns,inplace)**

| 参数    | 说明                                                        | 使用                             |
| ------- | ----------------------------------------------------------- | -------------------------------- |
| index   | 指定删除的行索引，列表可指定多个                            | df.drop(index=['学号','名字])    |
| columns | 指定要删除的列名                                            | df.drop(columns='列名')          |
| inplace | 是否覆盖原对象，如果为True，删除了会覆盖原对象，False则相反 | df.drop(index='行',inplace=True) |

**注：绘制异常值图表方法见第五点的箱图、直方图**

# 四、其它方法

### 1、分组聚合操作

分组聚合操作概念：按照某项规则对数据进行分组，接着对分完组的数据执行描述性统计的操作（比如求总和、求平均值）。

**语法：df.groupby(column).聚合操作**

> 对指定列进行分组：df.groupby('column')
>
> 按给定列顺序对数据进行多层分组：df.groupby(['columns1','columns2])
>
> 
>
> 注：分组聚合后数据比较乱，可以使用重置索引的方法将数据改为 DataFrame 数据 

```python
# 获取不同班级下不同性别的学生的平均分
df.groupby(['班级', '性别'])['成绩'].mean()
```

> 对分组的数据按组进行聚合计算。

##### 聚合运算

- **语法：Series.聚合函数()**

| **min**          | **求最小值**   |
| ---------------- | -------------- |
| **max**          | **最大值**     |
| **std**          | **标准差**     |
| **mean**         | **平均值**     |
| **median**       | **中位数**     |
| **sum**          | **总和**       |
| **count**        | **数量**       |
| **value_counts** | **求频数分布** |
| **mode**         | **众数**       |
| **max - min**    | **值域**       |

### 2、数据的排序

**语法：df.sort_values(by)，默认升序**

> 将数据按指定列进行排序

| 参数      | 说明                                                 |
| --------- | ---------------------------------------------------- |
| by        | 指定列名(axis=1或index) 或 索引值(axis=1或'columns') |
| ascending | 是否按指定列的数组升序排列，默认True，即升序         |
| inplace   | 是否用排序后的数据替换原数据，默认False不替换        |

```python
# 依照【总成绩】列的数据进行排序
df = df.sort_values(by='总成绩',ascending=False)
```

### 3、重置索引

**语法：s/df.reset_index(drop)**

> 将因经过数据处理而变得混乱的索引进行重置。
>
> 参数可以不写，都为默认。

| 参数    | 说明                                  |
| ------- | ------------------------------------- |
| drop    | 是否删除原索引，默认False不删除原索引 |
| inplace | 是否覆盖原对象                        |

```python
# 重置索引，且不保留原索引
reset_humans.reset_index(drop=True)
```

### 4、四舍五入

**语法：round()**

> 将数值型数据进行四舍五入。

| num         | 需要处理的数值，可以是int、dict、Series等 |
| ----------- | ----------------------------------------- |
| **ndigits** | **要保留的小数位数，默认0**               |

### 5、agg方法

用法一：

**语法：Series.agg(函数名)**

> 对 Series 整体应用指定函数并返回结果。

```python
# 调用函数
def func(data):
    if data == '-':
        data = 0
    return data
# 使用 agg() 方法对【数量】列的内容进行替换
foods_df['数量'] = foods_df['数量'].agg(func)
```

用法二：

**语法：DataFrame.agg({'列名1':'函数名1','列名2':'函数名2'})**

> 对 DataFrame 的列整体应用指定函数并返回结果。

```python
# 字典
# 同时计算【单价】列的最小值和【数量】列的最大值
foods_df.groupby('食品名').agg({'单价': 'min', '数量': 'max'})
```

### 6、类型转换

**方法一：转换单列**

**语法：df[字段].astype(type)**

```python
data_6['数量'].astype(int)

# 将时间转换为datetime64 类型
df['订单时间'].astype('datetime64')
```

**方法二：转换多列**

**语法：df.astype(dict)**

```python
df.astype({
    '订单时间':'datetime64',
    '第二列':'objects'
})
```

### 7、数据替换

**语法：s/df.replace(to_replace)**

> 根据给定的字典对 DataFrame 中的数据进行替换。

```python
# 将【性别】列的“难”替换为“男”，【城市】列的“.”替换为“未知”
df.replace({'难':'男', '.':'未知'})
```

# 五、matplotlib 绘图库

```python
# 导入 matplotlib 库的  pyplot 模块
from matplotlib import pyplot as plt
```

**简介：**

1、Python中最常用的第三方可视化库

2、绘图函数、参数较多，可以根据自己的风格自由选择，应用范围最广

### 1、设置字体

```PYTHON
# 设置中文字体
plt.rcParams['font.family'] = ['KaiTI']
```

| SimHei   | 黑体   |
| -------- | ------ |
| SimSun   | 宋体   |
| NSimSun  | 新宋体 |
| FangSong | 仿宋   |
| KaiTi    | 楷体   |

### 2、设置画布

```python
# figsize：设置画布     dpi：清晰度
plt.figure(figsize=(10,8),dpi=80)
```

### 3、选择图表

**折线图：plt.plot()**

```python
# 绘制折线图
plt.plot(x, y, color='dodgerblue')
```

| color     | 颜色                                     |
| --------- | ---------------------------------------- |
| label     | 标题                                     |
| linestyle | 线条样式                                 |
| x,y       | x：横坐标，y：纵坐标，可以为数组或者列表 |

- 特点

  ```python
  1）整体的走势；
  2）走势的规律性；
  3）走势的波动。
  ```

**柱状图：plt.bar(x，height)**

> height：设置柱子的高度

```python
# 画出柱状图
plt.bar(x, height, width=0.2)
```

**饼图：plt.pie(data,labels)**

> 输入一串数据，会绘制一个以数据总和为总体，按各部分所占比例占有面积的饼图。
>
> 
>
> labels：设置每个数据对应的名称。

```python
# 设置百分比小数的位数：保留百分比小数点后两位
autopct = '%.2f%%'
# 设置百分比字体大小和颜色
textprops = {'fontsize': 12, 'color': 'black'}
# 设置饼图的“爆炸效果”：让扇形远离圆心
explode = [0.1, 0, 0, 0]
# 设置不同扇形的颜色
colors = ['cornflowerblue', 'salmon', 'yellowgreen', 'orange']
# 绘制饼图
plt.pie(x, autopct=autopct, textprops=textprops,
        explode=explode, colors=colors)
```

| **autopct**    | **设置百分比显示**           |
| -------------- | ---------------------------- |
| **explode**    | **显示爆炸效果，对应labels** |
| **shadow**     | **显示阴影**                 |
| **frame**      | **显示框架**                 |
| **startangle** | **设置起始角度旋转**         |
| **data**       | **饼图数据**                 |
| **labels**     | **每个数据对应的名称**       |

**散点图：plt.scatter(x,y)**

> 绘制出平面内的所有数据点。

```python
x = ['180','122','111']
y = ['23','33','44']

plt.scatter(x,y)
```

**直方图：plt.hist()**

| 参数      | 说明         | 使用            |
| --------- | ------------ | --------------- |
|           | 设置柱形宽度 | 50              |
| density   | 显示密度     | density = True  |
| facecolor | 颜色         | facecolor = 'g' |
| alpha     | 透明度       | alpha = 0.75    |

画出直方图后，就可以结合 3σ 规则，利用平均值 μ 和标准偏差 σ 设计阈值，进而划分出异常值的范围。3σ 规则的计算流程是：
1）计算平均值 μ：可使用 df.mean()
2）计算标准差 σ：可使用 df.std()
3）计算阈值 μ-3σ 和 μ+3σ
4）遍历数据集，与阈值进行比较，位于 μ-3σ 和 μ+3σ 之间的是正常值，落在这个区间之外的是异常值

求异常值：

```python
# 平均值
m = df['付款金额'].mean()
# 标准差
std = df['付款金额'].std()

# 绘图
plt.hist(df['付款金额'],50,density = True,facecolor='g',alpha=0.75)
# 画线
plt.axvline(x = m + 3 * std ,color='red')
plt.axvline(x = m - 3 * std ,color='red')

plt.show()
```

**箱图：plt.boxplot()**

绘制出箱图后，就可以结合 1.5IQR 规则划分出异常值的范围。1.5IQR 规则的计算流程是：
1）计算第一个四分位值 Q1：可使用 df..quantile(0.25)
2）计算第三个四分位值 Q3：可使用 df..quantile(0.75)
3）计算 IQR = Q3 - Q1
4）遍历数据集进行比较，位于 Q1 - 1.5 * IQR 和 Q3 + 1.5 * IQR 之间的是正常值，落在这个区间之外的是异常值

```python
# 根据 1.5IQR 规则找到其中的正常值和异常值
Q1 = test_data['付款金额'].quantile(0.25)
Q3 = test_data['付款金额'].quantile(0.75)
IQR = Q3 - Q1
df_box_normal = test_data[(test_data['付款金额'] > Q1 - 1.5 * IQR ) & (test_data['付款金额'] < Q3 + 1.5 * IQR)]['付款金额']
df_box_outlier = test_data[(test_data['付款金额'] < Q1 - 1.5 * IQR ) | (test_data['付款金额'] > Q3 + 1.5 * IQR)]['付款金额']
# 画出正常集的箱图
plt.boxplot(df_box_normal)
plt.show()
# 画出异常集的箱图
plt.boxplot(df_box_outlier)
plt.show()
```

### 4、方法

**语法：plt.方法名**

| 方法名   | 说明          | 参数                                                         | 使用示例                                    |
| -------- | ------------- | ------------------------------------------------------------ | ------------------------------------------- |
| title    | 设置图表标题  | fontsize：设置字体大小                                       | plt.title('折线图')                         |
| x/ylabel | 设置x/y轴标题 | fontsize                                                     | plt.xlabel('x轴')                           |
| x/yticks | 设置x/轴刻度  | fontsize                                                     | plt.xticks(range(8))                        |
| legend   | 添加图例      | loc:放置的位置<br>best(合适位置)、upper left（左上方）、upper right（右上方） | plt.legend(['支持度', '置信度'],loc='best') |
| text     | 添加数据标签  | x、y：文字要显示的位置坐标<br>s：具体要添加的文字字符串<br/>color:设置颜色<br>ha：标签水平, `{'center', 'right', 'left'}`<br>va：对齐方式 |                                             |
| x/ylim   | 显示具体范围  | start:开始位置，end：结束位置                                | plt.xlim(5,10)                              |
| show     | 展示图表      | 无                                                           | plt.show()                                  |
| savefig  | 保存图表      | path：指定保存的路径                                         | plt.savefig('xxx.jpg')                      |

| 参数     | 说明                                                         | 使用                                   |
| -------- | ------------------------------------------------------------ | -------------------------------------- |
| fontsize | 设置字体大小                                                 | fontsize = 20                          |
| loc      | 放置图例的位置，best(合适位置)、upper left（左上方）、upper right（右上方） | loc = 'best'                           |
| labels   | 设置图例名称，列表                                           | labels = ['身高','体重']               |
| color    | 设置颜色                                                     | color = 'r'                            |
| fontdict | 不仅可设置图表标题的字体样式，还可以应用在坐标轴、图例、数据标签等图表元素中。 | fontdict = {'fontsize':20,'color':'r'} |
| rotation | 设置 rotation 参数来旋转刻度，rotation = 90 就是让刻度逆时针旋转 90 度 。 | rotation = 90                          |

# 六、Seaborn 绘图

```python
import seaborn as sns
```

### 1、折线图

**sns.lineplot(x,y,data)**

> x、y：分别指定横纵轴的DataFrame 的字段名
>
> data：DataFrame 数据
>
> palette：图形的调色板风格
>
> hue：在x、y的基础上进一步分类
>
> ci：等于None时表示不显示出误差区间

参数说明：x/y是横轴/纵轴字段，data是DataFrame数据

| 参数    | 说明                                                         | 使用示例     |
| ------- | ------------------------------------------------------------ | ------------ |
| style   | 可以用不同的折线的样式来表现各个类别                         | style='年份' |
| markers | 根据 `style` 所设置的参数类别选择不同的样式来标记折线上的数据点 | markers=True |
| dashes  | 为 `False` 可以不用虚线来区分 `style` 参数的类别，而只通过 `markers` 来区分 | dashes=True  |

### 2、柱状图

**sns.barplot(x,y,data)**

```python
sns.barplot(x='年份',y='付款金额',data=df)
```

> x ：横坐标的字段名
>
> y ：纵坐标的字段名
>
> data ：指定 DataFranme 数据

| 参数    | 说明                                     | 使用            |
| ------- | ---------------------------------------- | --------------- |
| hue     | 设置为某个字段就可以根据这个字段进行分类 | hue='星期几'    |
| palette | 设置图形的颜色风格                       | palette='Blues' |
| ci      | 用于将顶部的误差区间去掉                 | ci=None         |

### 3、箱图

**sns.boxplot(y,data)**

> x、y：为 dataframe 中想对其绘制箱图的字段名（x、y分别表示横纵坐标）
>
> data：DataFrame 数据
>
> 

| 参数      | 说明                             | 使用示例       |
| --------- | -------------------------------- | -------------- |
| palette   | 指图形的调色板风格               | palette='Reds' |
| hue       | 可以在x、y的基础上进一步分类     | hue='年份'     |
| linewidth | 箱图框线的粗细度，数字越小线越细 | linewidth=1    |
| width     | 每个箱的宽度，数字越小箱子越窄   | width=0.7      |
| fliersize | 异常点的大小                     | fliersize=0.1  |
| whis      | 异常值划分界限的系数             | whis=3         |
| notch     | 为True时，中位数那条线会凹陷一块 | notch=True     |



# 七、Apriori算法

### 1、概念

每条交易记录都可称为一个**事务**

交易中的不同物品可称为一个**项**

0个或多个**项的集合**，可称为一个**项集**，一般用`{X}`的形式表示项集，k 个项组成的项集，叫 k 项集

**支持度(Support)**可以表示项集在事务中出现的概率（频率），`{X}`的**支持度** = `{X}`在事务中出现的**次数** / 事务**总数**。

**最小支持度**，用于**筛掉**那些不符合需求的项集。被**留下来**的项集（≥ 最小支持度），被称为**频繁项集**。

**关联分析**是探索**数据之间联系**的技术，而数据之间的联系，我们用**关联规则**来表示，表达式为：`{X}→{Y}`（X 和 Y 之间不存在相同项）

**置信度(Confidence)**可用于衡量关联规则的**可靠程度**，表示在前件出现的情况下，后件出现的概率

关联规则`{X}→{Y}`的**置信度** = `{X，Y}`的**支持度** / `{X}`的**支持度**。

**最小置信度**，用于筛掉一些不符合需求的关联规则。

被留下来的关联规则（ ≥ 最小置信度），叫做**强关联规则**。

`{X}→{Y}`的**提升度** = `{X}→{Y}`的**置信度** / `{Y}`的**支持度**

提升度的值**小于1**，表示前件对后件是**抑制**的关系；

提升度**大于1**，表示前件对后件是**促进**的关系；

特别地当提升度的值**等于1**时，表示前件**不影响**后件，两者之间没有关系。

### 2、Apriori的使用

```python
# 导入 apyori 模块下的 apriori() 函数
from apyori import apriori
```

参数

| transactions   | 事务的集合，值可以是嵌套列表或Seeies对象 |
| -------------- | ---------------------------------------- |
| min_support    | 最小支持度，默认0.1                      |
| min_confidence | 最小置信度，默认0                        |
| min_lift       | 最小提升度，默认0                        |

使用案例：

```python
# 提取'文章类别'列数据，调用 apriori() 函数，设置最小支持度为 0.1 ，设置最小置信度 0.3
results = apriori(adjusted_data['文章类别'], min_support=0.1, min_confidence=0.3)

# 创建空列表，存储关联规则列表，形成嵌套列表
extract_result = []

for result in results:
    # 获取支持度,并保留 3 位小数
    support = round(result.support, 3)

    # 遍历ordered_statistics对象
    for rule in result.ordered_statistics:
        # 获取前件和后件并转成列表
        head_set = list(rule.items_base)
        tail_set = list(rule.items_add)

        # 跳过前件为空的数据
        if head_set == []:
            continue

        # 将前件、后件拼接成关联规则的形式
        related_catogory = str(head_set) + '→' + str(tail_set)

        # 提取置信度，并保留 3 位小数
        confidence = round(rule.confidence, 3)
        # 提取提升度，并保留 3 位小数
        lift = round(rule.lift, 3)

        # 将提取的数据保存到提取列表中
        extract_result.append(
            [related_catogory, support, confidence, lift])

# 将数据转成 DataFrame 的形式
rules_data = pd.DataFrame(extract_result, columns=[
                            '关联规则', '支持度', '置信度', '提升度'])
```

# 八、RFM模型

### 1、概念

- 简介

  ```python
  RFM模型是衡量客户价值和客户创利能力的重要工具和手段，它被广泛用于客户关系管理（CRM）的分析模式中。
  ```

- 特点

  ```
  RFM模型较为动态地显示了一个客户的全部轮廓，这对个性化的沟通和服务提供了依据，同时，如果与客户打交道的时间足够长，也能够较为准确地判断该客户的长期价值（甚至是终身价值），通过改善三项指标的状况，从而为更多的营销决策提供支持。
  ```

- **算法原理概念**

  ```python
  RFM 分别指最近一次消费时间间隔、消费频率、消费金额。
  
  
  Recency：上一次消费时间距离现在越近，用户的活跃度越大，用户的价值就越高。
  Frequency：购买频率越高，说明用户的忠诚度就越大，用户的价值就越高。
  Monetary：消费金额越高，说明用户的购买力越大，用户的价值就越高。
  ```

### 2、使用方法

![img](https://res.pandateacher.com/VMIXCWIM1627888155494.08)

- 算法流程

  ```
  1、计算 R、F、M 对应的数据。
  2、将三个指标进行分级评分。
  3、设置阈（yu）值，使得每个用户的三个指标对应被归为高或低。
  4、将三个指标的高低转换为 0 或 1 进行编码，对每一个编码贴上用户标签。
  ```
  
  ![img](https://res.pandateacher.com/6RJ9UPKH1627888264049.png)

**步骤：**

- 计算R、F、M数据

  ```python
  airline = airline[['会员卡号', '最近一次间隔天数', '近2年乘机次数', '近2年乘机金额']]
  ```

  ![img](https://res.pandateacher.com/IQZZV9NI1627271376022.49)

- 画条形图找评分区间

  ```python
  # 创建画布
  plt.figure(figsize=(6, 6)) 
  # 获取 airline 的【最近一次间隔天数】列数据
  x = airline['最近一次间隔天数'].sort_values()
  # 获取 airline 的索引
  y = airline.index
  
  # 绘制折线图
  plt.plot(x,y) 
  ```

  > x一般设置为排序后的值
  >
  > y一般设置为index索引值
  >
  > 
  >
  > 注：一般分为5个区间（根据折线图划出打分区间时，可以根据拐点判断，拐点右侧趋于平稳的作为一个区间，拐点左侧剩余部分再均匀划分。）
  >
  > 如果拐点不容易观察（使用 df.quantile() 方法来得到相应的分界点数值）：
  >
  > 可以打印出 20%，40%，60%，80% 分位的分界点，这样可以使五个区间的人数基本平均
  >
  > print('第一个分界点是：{}'.format(df_rfm['M'].quantile(0.2)))
  > print('第二个分界点是：{}'.format(df_rfm['M'].quantile(0.4)))
  > print('第三个分界点是：{}'.format(df_rfm['M'].quantile(0.6)))
  > print('第四个分界点是：{}'.format(df_rfm['M'].quantile(0.8)))

- 分别根据区间值划分R、F、M

  ```python
  # 定义函数按照区间划分标记 R 值
  def caculate_r(s):
      if s <= 140:
          return 5
      elif s <= 280:
          return 4
      elif s <= 420:
          return 3
      elif s <= 560:
          return 2
      else:
          return 1
  
  # 标记 R 值
  airline['R评分'] = airline['最近一次间隔天数'].agg(caculate_r)
  ```

  > 定义函数划分5个分段，再使用agg方法算出评分值

- 将评分值拼接成3个数字

  ```python
  # 计算R评分、F评分、M评分的平均数
  r_avg = airline['R评分'].mean()
  f_avg = airline['F评分'].mean()
  m_avg = airline['M评分'].mean()
  
  print('R评分的均值为：{}，F评分的均值为{},M评分的均值为{}'.format(r_avg, f_avg, m_avg))
  
  # 将R评分、F评分、M评分 的数据分别与对应的平均数做比较
  airline['R评分'] = (airline['R评分'] > r_avg) * 1
  airline['F评分'] = (airline['F评分'] > f_avg) * 1
  airline['M评分'] = (airline['M评分'] > m_avg) * 1
  
  # 拼接R评分、F评分、M评分
  rfm_score = airline['R评分'].astype(str) + airline['F评分'].astype(str) + airline['M评分'].astype(str)
  ```

  > 步骤：
  >
  > 1、计算R、F、M评分的平均数
  >
  > 2、如果评分值 > 平均数，则为1，否则为0
  >
  > 3、以字符串拼接的方式拼接第二步的数字

- 划分不同客户类型

  ```python
  # 定义字典标记 RFM 评分档对应的用户分类名称
  transform_label = {
      '111':'重要价值用户',
      '101':'重要发展用户',
      '011':'重要保持用户',
      '001':'重要挽留用户',
      '110':'一般价值用户',
      '100':'一般发展用户',
      '010':'一般保持用户',
      '000':'一般挽留用户'
  }
  # 将RFM评分替换成具体的客户类型
  airline['客户类型'] = rfm_score.replace(transform_label)
  ```

  > 步骤：
  >
  > 1、定义不同客户类型的列表
  >
  > 2、将拼接后的RFM替换为客户类型

  ![img](https://res.pandateacher.com/JMCPK9H51627269427866.16)

- 根据得到的分组按需求画图

  ```python
  # 对【客户类型】进行分组，再聚合【会员卡号】计算数量
  customer_data = airline.groupby('客户类型')['会员卡号'].count()
  ```

# 九、分析方法

**整体消费趋势分析：**

![img](https://res.pandateacher.com/KM3EZ5JF1626417199502.png)

**顾客个体消费分析：**

![img](https://res.pandateacher.com/G3ROF4UO1627012336810.png)



# 十、结论与建议

![img](https://res.pandateacher.com/4TCCTWRI1627291968466.png)

